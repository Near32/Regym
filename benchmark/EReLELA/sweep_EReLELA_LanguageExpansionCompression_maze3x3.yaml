project: EReLELA 
entity: near3213 
program: benchmark_wandb_erelela.py
command:
    - ${env}
    - ./venv/bin/python
    - ${program}
    - ${args}
method: bayes
metric:
    name: PerActor/Metrics/15_CoverageAndManipulationRatio_Mean
    goal: maximize
parameters:
    seed:
        values: [10, 20, 30]

    success_threshold:
        values: [0.5]

    use_cuda:
        values: [True]

    project:
        values: [EReLELA]

    config:
        values: [maze3x3_miniworld_wandb_benchmark_ETHER+R2D2+RP+ELA+SharedObsEncoder_config.yaml]

    language_guided_curiosity:
        values: [False]

    coverage_manipulation_metric:
        values: [True]

    MiniWorld_entity_visibility_oracle:
        values: [False]

    MiniWorld_entity_visibility_oracle_top_view:
        values: [False]

    use_ETHER:
        values: [False]
    use_THER:
        values: [False]

    use_RP:
        values: [False]
    RP_use_RP:
        values: [True]

    use_ELA:
        values: [True]
    ELA_use_ELA:
        values: [True]

    use_HER:
        values: [False]
    goal_oriented:
        values: [False]

    ETHER_use_ETHER:
        values: [False]
    THER_use_THER:
        values: [False]

    RP_use_PER:
        values: [True]

    RP_lock_test_storage:
        values: [False]

    RP_predictor_learning_rate:
        values: [6.25e-5]

    RP_gradient_clip:
        values: [5.0]

    RP_replay_capacity:
        values: [16384]
    RP_min_capacity:
        values: [32]

    RP_predictor_nbr_minibatches:
        values: [4]
    RP_predictor_batch_size:
        values: [256]

    RP_predictor_test_train_split_interval:
        values: [3]
    RP_test_replay_capacity:
        values: [1024]

    RP_test_min_capacity:
        values: [32]
    RP_replay_period:
        values: [1024]

    RP_nbr_training_iteration_per_update:
        values: [8]

    RP_predictor_accuracy_threshold:
        values: [90]

    ELA_rg_use_cuda:
        values: [True]

    ELA_rg_sanity_check_compactness_ambiguity_metric:
        values: [False]

    ELA_rg_shared_architecture:
        values: [True, False]

    ELA_rg_with_logits_mdl_principle:
        values: [True]

    ELA_rg_logits_mdl_principle_factor:
        values: [1.0e-3, 1.0e-4, 1.0e-5]

    ELA_rg_logits_mdl_principle_accuracy_threshold:
        values: [80.0, 60.0, 40.0]

    ELA_rg_agent_loss_type:
        values: [Impatient+Hinge]

    ELA_rg_use_semantic_cooccurrence_grounding:
        values: [False]

    ELA_rg_semantic_cooccurrence_grounding_lambda:
        values: [1.0]

    ELA_rg_semantic_cooccurrence_grounding_noise_magnitude:
        values: [0.2]

    ELA_lock_test_storage:
        values: [True]

    ELA_rg_color_jitter_prob:
        values: [0.0]

    ELA_rg_gaussian_blur_prob:
        values: [0.5, 0.0]

    ELA_rg_egocentric_prob:
        values: [0.5, 0.0]

    ELA_rg_object_centric_version:
        values: [2]
    ELA_rg_descriptive_version:
        values: [1]

    ELA_rg_learning_rate:
        values: [6.25e-5]
    ELA_rg_weight_decay:
        values: [0.0]

    ELA_rg_l1_weight_decay:
        values: [0.0, 1.0e-5]
    ELA_rg_l2_weight_decay:
        values: [0.0]

    ELA_rg_vocab_size:
        values: [64]
    ELA_rg_training_period:
        values: [8192]

    ELA_rg_descriptive:
        values: [False]
    ELA_rg_use_curriculum_nbr_distractors:
        values: [False]

    ELA_rg_nbr_epoch_per_update:
        values: [32, 8]
    ELA_rg_accuracy_threshold:
        values: [95]

    ELA_rg_nbr_train_distractors:
        values: [31, 15, 7]
    ELA_rg_nbr_test_distractors:
        values: [7]

    ELA_replay_capacity:
        values: [8192]
    ELA_test_replay_capacity:
        values: [1024]

    ELA_rg_distractor_sampling:
        values: [uniform, similarity-90]

    ELA_reward_extrinsic_weight:
        values: [0.0]
    ELA_reward_intrinsic_weight:
        values: [1.0]

    ELA_feedbacks_failure_reward:
        values: [0.0]
    ELA_feedbacks_success_reward:
        values: [1]

    BabyAI_Bot_action_override:
        values: [False]

    n_step:
        values: [3]
    nbr_actor:
        values: [32]
    eps_greedy_alpha:
        values: [2.0]

    nbr_minibatches:
        values: [1]
    batch_size:
        values: [64]

    min_capacity:
        values: [4e3]
    replay_capacity:
        values: [5e3]
    learning_rate:
        values: [6.25e-5]

    sequence_replay_burn_in_ratio:
        values: [0.5]
    weights_entropy_lambda:
        values: [0.0]

    sequence_replay_unroll_length:
        values: [20]
    sequence_replay_overlap_length:
        values: [10]

    sequence_replay_use_online_states:
        values: [True]
    sequence_replay_use_zero_initial_states:
        values: [False]

    sequence_replay_store_on_terminal:
        values: [False]
    HER_target_clamping:
        values: [False]

    adam_weight_decay:
        values: [0.0]
    ther_adam_weight_decay:
        values: [0.0]

    nbr_training_iteration_per_cycle:
        values: [1]
    nbr_episode_per_cycle:
        values: [0]

    single_pick_episode:
        values: [False, True]

    time_limit:
        values: [100]

    train_observation_budget:
        values: [5.0e4]



